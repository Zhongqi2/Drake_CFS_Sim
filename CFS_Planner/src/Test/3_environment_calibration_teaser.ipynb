{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    BaseField,\n",
    "    Box,\n",
    "    DepthImageToPointCloud,\n",
    "    DiagramBuilder,\n",
    "    Fields,\n",
    "    MeshcatPointCloudVisualizer,\n",
    "    MeshcatVisualizer,\n",
    "    Parser,\n",
    "    PixelType,\n",
    "    PointCloud,\n",
    "    Rgba,\n",
    "    RigidTransform,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    Simulator,\n",
    "    SpatialInertia,\n",
    "    StartMeshcat,\n",
    "    LeafSystem,\n",
    "    AbstractValue,\n",
    "    Concatenate,\n",
    ")\n",
    "from scipy.spatial import KDTree\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    Box,\n",
    "    Cylinder,\n",
    "    DiagramBuilder,\n",
    "    InverseKinematics,\n",
    "    MeshcatVisualizer,\n",
    "    MeshcatVisualizerParams,\n",
    "    RigidTransform,\n",
    "    Role,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    Parser,\n",
    "    Simulator,\n",
    "    InverseDynamicsController,\n",
    "    MakeRenderEngineVtk,\n",
    "    RenderEngineVtkParams,\n",
    "    CameraInfo,\n",
    "    RgbdSensor,\n",
    "    ClippingRange,\n",
    "    RenderCameraCore,\n",
    "    ColorRenderCamera,\n",
    "    DepthRenderCamera,\n",
    "    DepthRange,\n",
    "    FixedOffsetFrame,\n",
    "    AutoDiffXd,\n",
    "    InitializeAutoDiff,\n",
    "    Solve,\n",
    "    StartMeshcat,\n",
    ")\n",
    "from IPython.display import HTML, SVG, display, clear_output\n",
    "import cv2 as cv\n",
    "import open3d as o3d\n",
    "import time\n",
    "import teaserpp_python\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angular_error(R_gt, R_est):\n",
    "    \"\"\"\n",
    "    Get angular error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        A = (np.trace(np.dot(R_gt.T, R_est))-1) / 2.0\n",
    "        if A < -1:\n",
    "            A = -1\n",
    "        if A > 1:\n",
    "            A = 1\n",
    "        rotError = math.fabs(math.acos(A));\n",
    "        return math.degrees(rotError)\n",
    "    except ValueError:\n",
    "        import pdb; pdb.set_trace()\n",
    "        return 99999\n",
    "\n",
    "def compute_transformation_diff(est_mat, gt_mat):\n",
    "    \"\"\"\n",
    "    Compute difference between two 4-by-4 SE3 transformation matrix\n",
    "    \"\"\"\n",
    "    R_gt = gt_mat[:3,:3]\n",
    "    R_est = est_mat[:3,:3]\n",
    "    rot_error = get_angular_error(R_gt, R_est)\n",
    "\n",
    "    t_gt = gt_mat[:,-1]\n",
    "    t_est = est_mat[:,-1]\n",
    "    trans_error = np.linalg.norm(t_gt - t_est)\n",
    "\n",
    "    return rot_error, trans_error\n",
    "\n",
    "# read stl-generated model pcd\n",
    "def generate_model_pointcloud():\n",
    "\n",
    "    f = open('/home/ruic/Documents/MASCEI/Auto_calibration/config/geometry_wrappers/Bagging Machine.xyz')\n",
    "    data_lists = f.readline()\n",
    "\n",
    "    dataset= []\n",
    "    while data_lists:\n",
    "        num = list(map(float,data_lists.split()))\n",
    "        dataset.append(num)\n",
    "        data_lists = f.readline()\n",
    "    f.close()\n",
    "    data_array = np.array(dataset) # [N, 6]\n",
    "    cloud_val_raw = data_array.T # [6, N]\n",
    "    cloud_val_raw[[0,1,2],:] = cloud_val_raw[[0,1,2],:] * 0.001 # stl-generated in mm unit\n",
    "\n",
    "    # convert to point cloud\n",
    "    cloud_drake_raw = PointCloud(cloud_val_raw.shape[1])\n",
    "    cloud_drake_raw.mutable_xyzs()[:] = cloud_val_raw[[0,1,2],:]\n",
    "    \n",
    "    # assign normals\n",
    "    cloud_drake_raw.EstimateNormals(0.1, 6) # arbitrary, results are overridden\n",
    "    assert(cloud_drake_raw.has_normals())\n",
    "    cloud_drake_raw.mutable_normals()[:] = cloud_val_raw[[3,4,5],:]\n",
    "\n",
    "    cloud_drake = cloud_drake_raw.VoxelizedDownSample(voxel_size=0.01)\n",
    "\n",
    "    cloud_val = np.concatenate([cloud_drake.xyzs(), cloud_drake.normals()], axis=0)\n",
    "\n",
    "    return cloud_drake, cloud_val\n",
    "\n",
    "def save_cloud(fname, cloud_np):\n",
    "    '''\n",
    "        cloud_np: [6, N] np array\n",
    "    '''\n",
    "    # save 6d pcd as ply\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud_np[[0,1,2],:].T)\n",
    "    pcd.normals = o3d.utility.Vector3dVector(cloud_np[[3,4,5],:].T)\n",
    "    o3d.io.write_point_cloud(fname, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagger model size: (6, 15895)\n",
      "bagger scene size: (6, 15774)\n"
     ]
    }
   ],
   "source": [
    "meshcat = StartMeshcat()\n",
    "\n",
    "# --------------------- load the bagger model point cloud -------------------- #\n",
    "# model pcd model, model pcd values (6, N)\n",
    "bagger_model_cloud_drake, bagger_model_cloud_val = generate_model_pointcloud()\n",
    "# initial pose guess\n",
    "# X_model_default = RigidTransform(RollPitchYaw(np.pi /2, 0, np.pi/6), [0,0,0.64])\n",
    "\n",
    "# display\n",
    "# meshcat.SetObject(\"bagger_model\", bagger_model_cloud_drake, point_size=0.02, rgba=Rgba(0, 0, 1, 1))\n",
    "# meshcat.SetTransform(\"bagger_model\", X_model_default)\n",
    "\n",
    "print(f'bagger model size: {bagger_model_cloud_val.shape}')\n",
    "\n",
    "# --------------------- load the bagger scene point cloud -------------------- #\n",
    "bagger_scene_cloud_val_raw = np.loadtxt(\"bagger_scene_partial.txt\") # (6, M)\n",
    "bagger_scene_cloud_drake_raw = PointCloud(bagger_scene_cloud_val_raw.shape[1])\n",
    "bagger_scene_cloud_drake_raw.mutable_xyzs()[:] = bagger_scene_cloud_val_raw[[0,1,2],:] # assign xyz\n",
    "bagger_scene_cloud_drake_raw.EstimateNormals(0.1, 6) # arbitrary, results are overridden\n",
    "assert(bagger_scene_cloud_drake_raw.has_normals())\n",
    "bagger_scene_cloud_drake_raw.mutable_normals()[:] = bagger_scene_cloud_val_raw[[3,4,5],:] # assign normals\n",
    "bagger_scene_cloud_drake = bagger_scene_cloud_drake_raw.VoxelizedDownSample(voxel_size=0.01) # downsample\n",
    "bagger_scene_cloud_val = np.concatenate([bagger_scene_cloud_drake.xyzs(), bagger_scene_cloud_drake.normals()], axis=0)\n",
    "\n",
    "# display\n",
    "meshcat.SetObject(\"bagger_scene\", bagger_scene_cloud_drake, point_size=0.02, rgba=Rgba(0, 0, 0, 1))\n",
    "\n",
    "print(f'bagger scene size: {bagger_scene_cloud_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 15895)\n",
      "(6, 15774)\n"
     ]
    }
   ],
   "source": [
    "save_cloud(\"bagger_model.ply\", bagger_model_cloud_val)\n",
    "save_cloud(\"bagger_scene.ply\", bagger_scene_cloud_val)\n",
    "print(bagger_model_cloud_val.shape)\n",
    "print(bagger_scene_cloud_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPFH generates 131 putative correspondences.\n",
      "Starting scale solver (only selecting inliers if scale estimation has been disabled).\n",
      "Scale estimation complete.\n",
      "Max core number: 17\n",
      "Num vertices: 132\n",
      "Max Clique of scale estimation inliers: \n",
      "Using chain graph for GNC rotation.\n",
      "Starting rotation solver.\n",
      "GNC rotation estimation noise bound:0.1\n",
      "GNC rotation estimation noise bound squared:0.01\n",
      "GNC-TLS solver terminated due to cost convergence.\n",
      "Cost diff: 0\n",
      "Iterations: 11\n",
      "Rotation estimation complete.\n",
      "Starting translation solver.\n",
      "Translation estimation complete.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import teaserpp_python\n",
    "import numpy as np \n",
    "import copy\n",
    "from teaser_helpers import *\n",
    "\n",
    "VOXEL_SIZE = 0.05\n",
    "VISUALIZE = True\n",
    "\n",
    "# Load and visualize two point clouds from 3DMatch dataset\n",
    "A_pcd_raw = o3d.io.read_point_cloud('bagger_model.ply')\n",
    "B_pcd_raw = o3d.io.read_point_cloud('bagger_scene.ply')\n",
    "A_pcd_raw.paint_uniform_color([0.0, 0.0, 1.0]) # show A_pcd in blue\n",
    "B_pcd_raw.paint_uniform_color([1.0, 0.0, 0.0]) # show B_pcd in red\n",
    "if VISUALIZE:\n",
    "    o3d.visualization.draw_geometries([A_pcd_raw,B_pcd_raw]) # plot A and B \n",
    "\n",
    "# voxel downsample both clouds\n",
    "A_pcd = A_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "B_pcd = B_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "if VISUALIZE:\n",
    "    o3d.visualization.draw_geometries([A_pcd,B_pcd]) # plot downsampled A and B \n",
    "\n",
    "A_xyz = pcd2xyz(A_pcd) # np array of size 3 by N\n",
    "B_xyz = pcd2xyz(B_pcd) # np array of size 3 by M\n",
    "\n",
    "# extract FPFH features\n",
    "A_feats = extract_fpfh(A_pcd,VOXEL_SIZE)\n",
    "B_feats = extract_fpfh(B_pcd,VOXEL_SIZE)\n",
    "\n",
    "# establish correspondences by nearest neighbour search in feature space\n",
    "corrs_A, corrs_B = find_correspondences(\n",
    "    A_feats, B_feats, mutual_filter=True)\n",
    "A_corr = A_xyz[:,corrs_A] # np array of size 3 by num_corrs\n",
    "B_corr = B_xyz[:,corrs_B] # np array of size 3 by num_corrs\n",
    "\n",
    "num_corrs = A_corr.shape[1]\n",
    "print(f'FPFH generates {num_corrs} putative correspondences.')\n",
    "\n",
    "# visualize the point clouds together with feature correspondences\n",
    "points = np.concatenate((A_corr.T,B_corr.T),axis=0)\n",
    "lines = []\n",
    "for i in range(num_corrs):\n",
    "    lines.append([i,i+num_corrs])\n",
    "colors = [[0, 1, 0] for i in range(len(lines))] # lines are shown in green\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.visualization.draw_geometries([A_pcd,B_pcd,line_set])\n",
    "\n",
    "# robust global registration using TEASER++\n",
    "NOISE_BOUND = VOXEL_SIZE\n",
    "teaser_solver = get_teaser_solver(NOISE_BOUND)\n",
    "teaser_solver.solve(A_corr,B_corr)\n",
    "solution = teaser_solver.getSolution()\n",
    "R_teaser = solution.rotation\n",
    "t_teaser = solution.translation\n",
    "T_teaser = Rt2T(R_teaser,t_teaser)\n",
    "\n",
    "# Visualize the registration results\n",
    "A_pcd_T_teaser = copy.deepcopy(A_pcd).transform(T_teaser)\n",
    "o3d.visualization.draw_geometries([A_pcd_T_teaser,B_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99542196, -0.01963206,  0.0935398 , -0.808814  ],\n",
       "       [ 0.09471185,  0.07116946, -0.99295749,  0.8389051 ],\n",
       "       [ 0.01283663,  0.99727102,  0.07270304,  0.61842731],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meshcat.SetObject(\"bagger_model_detected\", bagger_model_cloud_drake, point_size=0.02, rgba=Rgba(1, 1, 0, 0.5))\n",
    "meshcat.SetTransform(\"bagger_model_detected\", RigidTransform(T_teaser))\n",
    "\n",
    "T_teaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing ICP...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.99992936,  0.00840288, -0.00840588, -0.81085253],\n",
       "       [-0.00849017,  0.01004621, -0.99991349,  1.1117348 ],\n",
       "       [-0.00831771,  0.99991423,  0.01011684,  0.6752882 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Performing ICP...')\n",
    "icp = cv.ppf_match_3d_ICP(1000, 0.01, 2.5, 6)\n",
    "results_ppf = [cv.ppf_match_3d_Pose3D()]\n",
    "results_ppf[0].updatePose(T_teaser)\n",
    "_, results_icp = icp.registerModelToScene(bagger_model_cloud_val.T, bagger_scene_cloud_val.T, results_ppf)\n",
    "\n",
    "meshcat.SetObject(\"bagger_model_ICP_refined\", bagger_model_cloud_drake, point_size=0.02, rgba=Rgba(0, 1, 0, 1))\n",
    "meshcat.SetTransform(\"bagger_model_ICP_refined\", RigidTransform(results_icp[0].pose))\n",
    "\n",
    "results_icp[0].pose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mascei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
